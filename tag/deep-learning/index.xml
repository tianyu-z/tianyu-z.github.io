<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning | Tianyu Zhang's WebPage</title><link>https://tyz.netlify.app/tag/deep-learning/</link><atom:link href="https://tyz.netlify.app/tag/deep-learning/index.xml" rel="self" type="application/rss+xml"/><description>Deep Learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 08 Apr 2023 00:00:00 +0000</lastBuildDate><image><url>https://tyz.netlify.app/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Deep Learning</title><link>https://tyz.netlify.app/tag/deep-learning/</link></image><item><title>Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation</title><link>https://tyz.netlify.app/publication/clap/</link><pubDate>Sat, 08 Apr 2023 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/publication/clap/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://arxiv.org/abs/2211.06687" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>Multi-Agent Reinforcement Learning for Fast-Timescale Demand Response of Residential Loads</title><link>https://tyz.netlify.app/publication/egrid2/</link><pubDate>Fri, 06 Jan 2023 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/publication/egrid2/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://arxiv.org/abs/2301.02593" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>Biological Sequence Design with GFlowNets</title><link>https://tyz.netlify.app/publication/biological-sequence-design-with-gflownets/</link><pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/publication/biological-sequence-design-with-gflownets/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://proceedings.mlr.press/v162/jain22a.html" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>Multi-agent reinforcement learning for renewable integration in the electric power grid</title><link>https://tyz.netlify.app/publication/egrid/</link><pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/publication/egrid/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://www.climatechange.ai/papers/neurips2021/71" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods</title><link>https://tyz.netlify.app/publication/climategan-raising-climate-change-awareness-by-generating-images-of-floods/</link><pubDate>Wed, 06 Oct 2021 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/publication/climategan-raising-climate-change-awareness-by-generating-images-of-floods/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://openreview.net/forum?id=EZNOb_uNpJk" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>CLAP</title><link>https://tyz.netlify.app/project/audioclip/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/project/audioclip/</guid><description>&lt;p>Contrastive learning has shown remarkable success in the field of multimodal representation learning. In this paper, we propose a pipeline of contrastive language-audio pretraining to develop an audio representation by combining audio data with natural language descriptions. To accomplish this target, we first release LAION-Audio-630K, a large collection of 633,526 audio-text pairs from different data sources. Second, we construct a contrastive language-audio pretraining model by considering different audio encoders and text encoders. We incorporate the feature fusion mechanism and keyword-to-caption augmentation into the model design to further enable the model to process audio inputs of variable lengths and enhance the performance. Third, we perform comprehensive experiments to evaluate our model across three tasks: text-to-audio retrieval, zero-shot audio classification, and supervised audio classification. The results demonstrate that our model achieves superior performance in text-to-audio retrieval task. In audio classification tasks, the model achieves state-of-the-art performance in the zero-shot setting and is able to obtain performance comparable to models&amp;rsquo; results in the non-zero-shot setting. LAION-Audio-630K and the proposed model are both available to the public.&lt;/p></description></item><item><title>MARL for Renewable Integration in the Electric Power Grid</title><link>https://tyz.netlify.app/project/egrid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/project/egrid/</guid><description>&lt;p>As part of the fight against climate change, the electric power system is transitioning from fuel-burning generators to renewable sources of power like wind and solar. To allow for the grid to rely heavily on renewables, important operational changes must be done. For example, novel approaches for frequency regulation, ie, for balancing in real-time demand and generation, are required to ensure the stability of a renewable electric system. Demand response programs in which loads adjust in part their power consumption for the grid’s benefit, can be used to provide frequency regulation. In this proposal, we present and motivate a collaborative multi-agent reinforcement learning approach to meet the algorithmic requirements for providing real-time power balancing with demand response.&lt;/p>
&lt;p>Please check here for &lt;a href="https://www.climatechange.ai/papers/neurips2021/71" target="_blank" rel="noopener">the full proposal&lt;/a>.&lt;/p></description></item><item><title>Multi Agent Cooperation in Game Theory</title><link>https://tyz.netlify.app/project/agentcooperation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/project/agentcooperation/</guid><description>&lt;p>Developed based on &lt;a href="https://arxiv.org/abs/1709.04326" target="_blank" rel="noopener">LOLA&lt;/a> and &lt;a href="https://arxiv.org/abs/2103.04931" target="_blank" rel="noopener">MCTS&lt;/a>, the goal is to find a mechanism for the so that the agents can converge to a cooperate-cooperate equilibrium in game such as the coin game or prisoner&amp;rsquo;s dilemma game. We aim to find a scalable solution.&lt;/p></description></item><item><title>RICE-N | AI for Global Climate Cooperation</title><link>https://tyz.netlify.app/project/climatecoop/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://tyz.netlify.app/project/climatecoop/</guid><description>&lt;p>RICE-N simulator wins the &lt;a href="https://www.events.netexplo.com/forum-innovation-2023/content/rice-n" target="_blank" rel="noopener">Netexplo Innovation Award in 2023&lt;/a>.
We believe this &lt;a href="https://www.ai4climatecoop.org/" target="_blank" rel="noopener">competition&lt;/a> opens the way for beneficial contributions to several different areas in research and policy.&lt;/p>
&lt;p>Researchers and engineers: Whether it be in Economics, Machine Learning, Agent-based Modelling, Game Theory, Political Science, Behavioral Science, Mathematics, Computer Science, Complex Systems or any other discipline you believe to be relevant, this competition identifies and creates many opportunities for innovation. For example, negotiation protocols between different regions are one of the keys to the encourage climate mitigation. One of the goal of this competition is to design a negotiation mechanism between different regions so that agents may not only maximize their own utility but also care more about the collective goal — carbon emission mitigation We envision diversity as a strength, not a weakness. Solving problems that affect each and every person calls for transversal thinking, multifaceted contributions and collaboration.&lt;/p>
&lt;p>Policy writers and makers: Transmuting good research into tangible political results creates long lasting change, and properly communicating outcomes to governments is just as necessary as the research itself. We envision clear communication and actionable, targeted recommendations as a pillar of change and an important skill for anyone looking to make an impact.&lt;/p>
&lt;p>To learn more, please check our &lt;a href="https://www.ai4climatecoop.org/" target="_blank" rel="noopener">official website&lt;/a>.&lt;/p></description></item></channel></rss>