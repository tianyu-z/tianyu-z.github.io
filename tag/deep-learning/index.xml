<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning | Tianyu Zhang's WebPage</title><link>https://ai.t-zhang.com/tag/deep-learning/</link><atom:link href="https://ai.t-zhang.com/tag/deep-learning/index.xml" rel="self" type="application/rss+xml"/><description>Deep Learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 25 May 2025 00:00:00 +0000</lastBuildDate><image><url>https://ai.t-zhang.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Deep Learning</title><link>https://ai.t-zhang.com/tag/deep-learning/</link></image><item><title>STRICT: Stress Test of Rendering Images Containing Text</title><link>https://ai.t-zhang.com/publication/strict/</link><pubDate>Sun, 25 May 2025 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/strict/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://proceedings.iclr.cc/paper_files/paper/2025/hash/812e3f4ff9877b318689a22d81172cf3-Abstract-Conference.html" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>MuPT: A Generative Symbolic Music Pretrained Transformer</title><link>https://ai.t-zhang.com/publication/mupt/</link><pubDate>Mon, 05 May 2025 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/mupt/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://proceedings.iclr.cc/paper_files/paper/2025/hash/73f6f8897896f7bda86ea7d1ebc1dc4f-Abstract-Conference.html" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>MAP: Low-compute Model Merging with Amortized Pareto Fronts via Quadratic Approximation</title><link>https://ai.t-zhang.com/publication/map/</link><pubDate>Mon, 28 Apr 2025 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/map/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://proceedings.iclr.cc/paper_files/paper/2025/hash/a3724221b623bf1966e92cd266ac6177-Abstract-Conference.html" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>BigDocs: An Open and Permissively-Licensed Dataset for Training Multimodal Models on Document and Code Tasks</title><link>https://ai.t-zhang.com/publication/bigdocs/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/bigdocs/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://proceedings.iclr.cc/paper_files/paper/2025/hash/c4659191ae1e89faa09864c23fa91f31-Abstract-Conference.html" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation</title><link>https://ai.t-zhang.com/publication/clap/</link><pubDate>Sat, 08 Apr 2023 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/clap/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://arxiv.org/abs/2211.06687" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>Multi-Agent Reinforcement Learning for Fast-Timescale Demand Response of Residential Loads</title><link>https://ai.t-zhang.com/publication/egrid2/</link><pubDate>Fri, 06 Jan 2023 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/egrid2/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://arxiv.org/abs/2301.02593" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>Biological Sequence Design with GFlowNets</title><link>https://ai.t-zhang.com/publication/biological-sequence-design-with-gflownets/</link><pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/biological-sequence-design-with-gflownets/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://proceedings.mlr.press/v162/jain22a.html" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item><item><title>ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods</title><link>https://ai.t-zhang.com/publication/climategan-raising-climate-change-awareness-by-generating-images-of-floods/</link><pubDate>Wed, 06 Oct 2021 00:00:00 +0000</pubDate><guid>https://ai.t-zhang.com/publication/climategan-raising-climate-change-awareness-by-generating-images-of-floods/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>&lt;a href="https://openreview.net/forum?id=EZNOb_uNpJk" target="_blank" rel="noopener">Paper&lt;/a>&lt;/p></description></item></channel></rss>